{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built with sktime 0.5.2\n",
    "# install conda environment file from environment.yml file in your command line: conda env create -f environment.yml\n",
    "# download sktime through: conda install -c conda-forge sktime\n",
    "# or download and install latest sktime development version using the instructions on the file \"sktime installation from git.txt\"\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "from sktime.benchmarking.data import UEADataset, make_datasets\n",
    "from sktime.benchmarking.evaluation import Evaluator\n",
    "from sktime.benchmarking.metrics import PairwiseMetric, AggregateMetric\n",
    "from sktime.benchmarking.orchestration import Orchestrator\n",
    "from sktime.benchmarking.results import HDDResults\n",
    "from sktime.benchmarking.strategies import TSCStrategy\n",
    "from sktime.benchmarking.tasks import TSCTask\n",
    "from sktime.series_as_features.model_selection import PresplitFilesCV\n",
    "\n",
    "\n",
    "\n",
    "from sktime.classification.compose import (\n",
    "    ColumnEnsembleClassifier,\n",
    "    TimeSeriesForestClassifier,\n",
    ")\n",
    "\n",
    "from sktime.classification.dictionary_based import (\n",
    "    IndividualBOSS,\n",
    "    BOSSEnsemble,\n",
    "    ContractableBOSS,\n",
    "    TemporalDictionaryEnsemble,\n",
    "    IndividualTDE,\n",
    "    WEASEL,\n",
    "    MUSE,\n",
    ")\n",
    "\n",
    "from sktime.classification.shapelet_based import (\n",
    "    MrSEQLClassifier,\n",
    "    ShapeletTransformClassifier,\n",
    ")\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForest, RandomIntervalSpectralForest\n",
    "\n",
    "\n",
    "from sktime.classification.distance_based import (\n",
    "    ElasticEnsemble,\n",
    "    ProximityTree,\n",
    "    ProximityForest,\n",
    "    ProximityStump,\n",
    ")\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sktime\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "\n",
    "# dowload http://www.timeseriesclassification.com/Downloads/Archives/Multivariate2018_ts.zip and extract to your desired path\n",
    "# change data path to the path where Multivariate_ts folder exists\n",
    "DATA_PATH = os.path.join(os.path.dirname(\"C:\\\\Users\\\\rbabayev\\\\Desktop\\\\\"), \"Multivariate_ts\")\n",
    "#RESULTS_PATH = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_multivariate(X):\n",
    "    import pandas\n",
    "    if type(X) == pandas.core.frame.DataFrame and len(X.shape) == 2:\n",
    "        return X.shape[1] > 1\n",
    "    else:\n",
    "        return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should run test for each dataset one by one by uncommenting them\n",
    "\n",
    "# length of the series is 207\n",
    "X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "    os.path.join(DATA_PATH, \"Epilepsy/Epilepsy_TRAIN.ts\")\n",
    ")\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "    os.path.join(DATA_PATH, \"Epilepsy/Epilepsy_TEST.ts\")\n",
    ")\n",
    "\n",
    "\n",
    "# # length of the series is 50\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"FingerMovements/FingerMovements_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"FingerMovements/FingerMovements_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "# # length of the series is 400\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"HandMovementDirection/HandMovementDirection_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"HandMovementDirection/HandMovementDirection_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "# # length of series is 405\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"Heartbeat/Heartbeat_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"Heartbeat/Heartbeat_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # length of the series is 100\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"BasicMotions/BasicMotions_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"BasicMotions/BasicMotions_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# # length of the series is 896\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"SelfRegulationSCP1/SelfRegulationSCP1_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"SelfRegulationSCP1/SelfRegulationSCP1_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "# # length of the series is 1152\n",
    "# X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"SelfRegulationSCP2/SelfRegulationSCP2_TRAIN.ts\")\n",
    "# )\n",
    "# X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"SelfRegulationSCP2/SelfRegulationSCP2_TEST.ts\")\n",
    "# )\n",
    "\n",
    "\n",
    "# download http://www.timeseriesclassification.com/Downloads/EyesOpenShut.zip \n",
    "# and extract EyesOpenShut_TRAIN.arff and EyesOpenShut_TEST.arff to your desired path\n",
    "# # path for multivariate datasets which are not available in the UEA and UCR zip files\n",
    "# o_path = os.path.join(os.path.dirname(\"C:\\\\Users\\\\rbabayev\\\\Desktop\\\\\"), \"Other_datasets_arff\\\\multivariate\")\n",
    "\n",
    "\n",
    "# # length of the time series is 128\n",
    "# X_train, y_train = load_from_arff_to_dataframe(\n",
    "#     os.path.join(o_path, \"EyesOpenShut/EyesOpenShut_TRAIN.arff\")\n",
    "# )\n",
    "# X_test, y_test = load_from_arff_to_dataframe(\n",
    "#     os.path.join(o_path, \"EyesOpenShut/EyesOpenShut_TEST.arff\")\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Multivariate dataset -> \", is_multivariate(X_train))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class target variable\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column ensembling\n",
    "# We can also fit one classifier for each time series column and then aggregated their predictions. \n",
    "# The interface is similar to the familiar ColumnTransformer from sklearn.\n",
    "\n",
    "clf_list = [\n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"TSFC0\", TimeSeriesForestClassifier(n_estimators=100, random_state=1), [0]),\n",
    "#     ]\n",
    "# ),\n",
    "    \n",
    "    ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"TSF0\", TimeSeriesForest(n_estimators=100, random_state=1), [0]),\n",
    "    ]\n",
    "),\n",
    "    \n",
    "    ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomIntervalSpectralForest0\", RandomIntervalSpectralForest(n_estimators=100, random_state=1), [0]),\n",
    "    ]\n",
    "),\n",
    "    \n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"BOSSEnsemble0\", BOSSEnsemble(max_ensemble_size=5, random_state=1), [0]),\n",
    "#     ]\n",
    "# ),\n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"TemporalDictionaryEnsemble0\", TemporalDictionaryEnsemble(n_parameter_samples=250, max_ensemble_size=50,\n",
    "#                                                                    randomly_selected_params=50, random_state=1), [0])\n",
    "#     ]\n",
    "# ),\n",
    "   ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"KNeighborsTimeSeriesClassifier0\", KNeighborsTimeSeriesClassifier(n_neighbors=1, metric=\"dtw\"), [0])\n",
    "    ]\n",
    "),  \n",
    "    \n",
    "    ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"ContractableBOSS0\", ContractableBOSS(n_parameter_samples=250, max_ensemble_size=50, random_state=1), [0])\n",
    "    ]\n",
    "),  \n",
    "    \n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"CanonicalIntervalForest0\", CanonicalIntervalForest(n_estimators=100, att_subsample_size=8, random_state=1), [0])\n",
    "#     ]\n",
    "# ),  \n",
    "    \n",
    "    \n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"STC0\", ShapeletTransformClassifier(time_contract_in_mins=1, random_state=1), [0])\n",
    "#     ]\n",
    "# ),  \n",
    "    \n",
    "    ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"WSL0\", WEASEL(binning_strategy=\"equi-depth\", anova=False, random_state=1), [0])\n",
    "    ]\n",
    "),  \n",
    "    \n",
    "#     ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"EE0\", ElasticEnsemble(random_state=1), [0])\n",
    "#     ]\n",
    "# ),  \n",
    "    \n",
    "#      ColumnEnsembleClassifier(\n",
    "#     estimators=[\n",
    "#         (\"PF0\", ProximityForest(n_estimators=100, random_state=1), [0])\n",
    "#     ]\n",
    "# ),  \n",
    "    \n",
    "    MrSEQLClassifier(),\n",
    "    MUSE(random_state=1),\n",
    "]\n",
    "\n",
    "\n",
    "for clf in clf_list:\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_prob = clf.predict_proba(X_test)\n",
    "    y_test_pred = clf.predict(X_test) \n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"f1 score: \", f1_score(y_test, y_test_pred, average='macro'))\n",
    "    \n",
    "    if len(np.unique(y_train)) == 2:\n",
    "        # for binary classification make_scorer should be used: https://github.com/scikit-learn/scikit-learn/issues/10247\n",
    "        print(\"auroc: \", make_scorer(roc_auc_score, needs_proba=True)(clf, X_test, y_test))\n",
    "    else:\n",
    "        print(\"auroc: \", roc_auc_score(y_test, y_test_prob, average='macro', multi_class=\"ovo\"))\n",
    "        \n",
    "    #print(\"auprc: \", average_precision_score(y_test, y_test_prob)) # multiclass format is not supported\n",
    "    #print(\"auprc: \", make_scorer(average_precision_score, needs_proba=True)(clf, X_test, y_test)) # multiclass format is not supported\n",
    "    print(\"recall: \", recall_score(y_test, y_test_pred, average='macro'))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bespoke classification algorithms\n",
    "# Another approach is to use bespoke (or classifier-specific) methods for multivariate time series data.\n",
    "# Here, we try out the MrSEQL algorithm in multidimensional space.\n",
    "\n",
    "# clf = MrSEQLClassifier()\n",
    "\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"accuracy: \", clf.score(X_test, y_test))\n",
    "# y_test_pred = clf.predict(X_test)\n",
    "# y_test_prob = clf.predict_proba(X_test)\n",
    "# print(\"f1 score: \", f1_score(y_test, y_test_pred, average='macro'))\n",
    "# print(\"auroc: \", roc_auc_score(y_test, y_test_prob, average='macro', multi_class=\"ovo\"))\n",
    "# #print(\"auprc: \", average_precision_score(y_test, y_test_prob)) # multiclass format is not supported\n",
    "# print(\"recall: \", recall_score(y_test, y_test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = MUSE(random_state=1)\n",
    "\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"accuracy: \", clf.score(X_test, y_test))\n",
    "# y_test_pred = clf.predict(X_test)\n",
    "# y_test_prob = clf.predict_proba(X_test)\n",
    "# print(\"f1 score: \", f1_score(y_test, y_test_pred, average='macro'))\n",
    "# print(\"auroc: \", roc_auc_score(y_test, y_test_prob, average='macro', multi_class=\"ovo\"))\n",
    "# #print(\"auprc: \", average_precision_score(y_test, y_test_prob)) # multiclass format is not supported\n",
    "# print(\"recall: \", recall_score(y_test, y_test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
